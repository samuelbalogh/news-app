export const AI_WORDS = new Set([
    'ai', 'machine', 'learning', 'neural', 'network', 'deep', 'artificial intelligence',
    'nvidia', 'openai', 'google', 'meta', 'microsoft', 'apple', 'amazon', 'tesla', 'spacex', 'nasa',
    'nlp', 'llm', 'gpt', 'llama', 'chatgpt', 'gpt-4', 'gpt-3.5', 'gpt-3', 'gpt-2', 'gpt-1', 'gpt-0',
    'claude', 'groq', 'grok', 'grok-2', 'grok-1', 'grok-0',
    'transformer', 'bert', 'roberta', 'attention', 'reinforcement', 'vision', 'computer', 'mlops',
    'embeddings', 'vector', 'tensor', 'pytorch', 'tensorflow', 'keras', 'jax', 'huggingface', 'anthropic',
    'cohere', 'gemini', 'mistral', 'diffusion', 'stable', 'midjourney', 'dall-e', 'sora', 'multimodal',
    'rag', 'retrieval', 'augmented', 'generation', 'agentic', 'agent', 'fine-tuning', 'prompt', 'token',
    'tokenizer', 'semantic', 'reasoning', 'hallucination', 'bias', 'safety', 'alignment', 'ethics',
    'synthetic', 'data', 'dataset', 'training', 'inference', 'latency', 'quantization', 'bfloat16',
    'autoregressive', 'generative', 'foundation', 'model', 'modality', 'perplexity', 'parameter',
    'billion', 'trillion', 'mixtral', 'optimization', 'gradient', 'backpropagation'
])

export const STOP_WORDS = new Set([
    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he',
    'in', 'is', 'it', 'its', 'of', 'on', 'that', 'the', 'to', 'was', 'were',
    'will', 'with', 'this', 'but', 'they', 'have', 'had', 'what', 'when',
    'where', 'who', 'which', 'why', 'how', 'all', 'any', 'both', 'each', 'few',
    'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',
    'same', 'so', 'than', 'too', 'very', 'can', 'just', 'should', 'now', 'our',
    'your', 'their', 'there', 'here', 'whom', 'these', 'those', 'my', 'his', 'her',
    'whoever', 'whomever', 'whatever', 'whichever', 'you'
])

export const MIN_WORD_LENGTH = 3
export const MIN_WORD_FREQUENCY = 2

